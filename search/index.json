[{"content":"","date":"2025-07-31T13:10:19+08:00","permalink":"https://Strivy-ZSY.github.io/p/litesegformer3d/","title":"LiteSegFormer3D"},{"content":"TL;DR 本文提出了一种混合递归结构，通过令牌和专家路由进行token过滤，KV缓存进行内存节省，在7个样本中以更少的参数实现了超过基线的性能，对Transformer模型的结构有一定的优化意义。\n研究动机 (Motivation) 背景 (Background) 随着大语言模型规模的扩大，随之计算和内存的要求也越高，在除数据中心外的地方难以训练和部署，因此对模型效率的优化显得尤为重要。\n现有方法的局限性 (Gap/Limitations of Existing Work) 现有的两种优化方式分别是减少或共享模型权重和仅在需要的时候增加计算开销，但能有效统一参数效率和自适应计算的架构仍然缺失\n本文价值 (Value Proposition) 本文通过端到端的轻量级路由器为每个token分配固定的递归深度，并根据思考深度决定共享参数块应用次数，同时该token递归机制天然的支持KV缓存，选择性的存储和检索对应的键值对。\n解决的关键问题与贡献 (Key Problem Solved \u0026amp; Contribution) 解决的关键技术问题 MoR能在每个token的解码阶段实现潜在思考，同时路由机制促进了模型的自适应推理，突破了先前工作常见的固定思考深度。总的来说，MoR使得模型能根据每个token高效的调整其思考深度，将参数效率与自适应统一起来。\n核心贡献 罗列作者的解决方法\n提出的架构-\u0026gt;核心模块-\u0026gt;数据集实验验证-\u0026gt;性能/SOTA？\n方法详述 (Method) 罗列每个模块的方法，公式，网络图，作用\n实验分析 (Experiments) 罗列数据集上和诸多模型的对比效果\n消融实验 (Ablation Analysis) 批判性思考 (Critical Analysis \u0026amp; Personal Thoughts) 优点 (Strengths) 自己对该论文优势的总结\n潜在缺点/可疑点 (Weaknesses/Questions) 模型复杂度？在特定场景的泛化能力？理论基础？\n启发/可借鉴点 (Insights/Takeaways) 该论文值得借鉴的地方\n","date":"2025-07-31T12:31:09+08:00","image":"https://Strivy-ZSY.github.io/p/mixture-of-recursions/mor_fig1_hu_86037966b0f8a25d.png","permalink":"https://Strivy-ZSY.github.io/p/mixture-of-recursions/","title":"Mixture of Recursions"}]