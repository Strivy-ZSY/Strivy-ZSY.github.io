<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Strivy</title>
        <link>https://Strivy-ZSY.github.io/post/</link>
        <description>Recent content in Posts on Strivy</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>Strivy</copyright>
        <lastBuildDate>Thu, 31 Jul 2025 13:10:19 +0800</lastBuildDate><atom:link href="https://Strivy-ZSY.github.io/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>LiteSegFormer3D</title>
        <link>https://Strivy-ZSY.github.io/p/litesegformer3d/</link>
        <pubDate>Thu, 31 Jul 2025 13:10:19 +0800</pubDate>
        
        <guid>https://Strivy-ZSY.github.io/p/litesegformer3d/</guid>
        <description></description>
        </item>
        <item>
        <title>Mixture of Recursions</title>
        <link>https://Strivy-ZSY.github.io/p/mixture-of-recursions/</link>
        <pubDate>Thu, 31 Jul 2025 12:31:09 +0800</pubDate>
        
        <guid>https://Strivy-ZSY.github.io/p/mixture-of-recursions/</guid>
        <description>&lt;img src="https://Strivy-ZSY.github.io/p/mixture-of-recursions/mor_fig1.png" alt="Featured image of post Mixture of Recursions" /&gt;&lt;h2 id=&#34;tldr&#34;&gt;TL;DR
&lt;/h2&gt;&lt;p&gt;本文提出了一种混合递归结构，通过令牌和专家路由进行token过滤，KV缓存进行内存节省，在7个样本中以更少的参数实现了超过基线的性能，对Transformer模型的结构有一定的优化意义。&lt;/p&gt;
&lt;h2 id=&#34;研究动机-motivation&#34;&gt;研究动机 (Motivation)
&lt;/h2&gt;&lt;h3 id=&#34;背景-background&#34;&gt;背景 (Background)
&lt;/h3&gt;&lt;p&gt;随着大语言模型规模的扩大，随之计算和内存的要求也越高，在除数据中心外的地方难以训练和部署，因此对模型效率的优化显得尤为重要。&lt;/p&gt;
&lt;h3 id=&#34;现有方法的局限性-gaplimitations-of-existing-work&#34;&gt;现有方法的局限性 (Gap/Limitations of Existing Work)
&lt;/h3&gt;&lt;p&gt;现有的两种优化方式分别是&lt;strong&gt;减少或共享模型权重&lt;/strong&gt;和&lt;strong&gt;仅在需要的时候增加计算开销&lt;/strong&gt;，但能有效统一参数效率和自适应计算的架构仍然缺失&lt;/p&gt;
&lt;h3 id=&#34;本文价值-value-proposition&#34;&gt;本文价值 (Value Proposition)
&lt;/h3&gt;&lt;p&gt;本文通过端到端的轻量级路由器为每个token分配固定的递归深度，并根据思考深度决定共享参数块应用次数，同时该token递归机制天然的支持KV缓存，选择性的存储和检索对应的键值对。&lt;/p&gt;
&lt;h2 id=&#34;解决的关键问题与贡献-key-problem-solved--contribution&#34;&gt;解决的关键问题与贡献 (Key Problem Solved &amp;amp; Contribution)
&lt;/h2&gt;&lt;h3 id=&#34;解决的关键技术问题&#34;&gt;解决的关键技术问题
&lt;/h3&gt;&lt;p&gt;MoR能在每个token的解码阶段实现潜在思考，同时路由机制促进了模型的自适应推理，突破了先前工作常见的固定思考深度。总的来说，MoR使得模型能根据每个token高效的调整其思考深度，将参数效率与自适应统一起来。&lt;/p&gt;
&lt;h3 id=&#34;核心贡献&#34;&gt;核心贡献
&lt;/h3&gt;&lt;p&gt;&lt;font color=&#34;#c0504d&#34;&gt;罗列&lt;/font&gt;作者的解决方法&lt;/p&gt;
&lt;p&gt;提出的架构-&amp;gt;核心模块-&amp;gt;数据集实验验证-&amp;gt;性能/SOTA？&lt;/p&gt;
&lt;h2 id=&#34;方法详述-method&#34;&gt;方法详述 (Method)
&lt;/h2&gt;&lt;p&gt;&lt;font color=&#34;#c0504d&#34;&gt;罗列&lt;/font&gt;每个模块的方法，公式，网络图，作用&lt;/p&gt;
&lt;h2 id=&#34;实验分析-experiments&#34;&gt;实验分析 (Experiments)
&lt;/h2&gt;&lt;p&gt;&lt;font color=&#34;#c0504d&#34;&gt;罗列&lt;/font&gt;数据集上和诸多模型的对比效果&lt;/p&gt;
&lt;h3 id=&#34;消融实验-ablation-analysis&#34;&gt;消融实验 (Ablation Analysis)
&lt;/h3&gt;&lt;h2 id=&#34;批判性思考-critical-analysis--personal-thoughts&#34;&gt;批判性思考 (Critical Analysis &amp;amp; Personal Thoughts)
&lt;/h2&gt;&lt;h3 id=&#34;优点-strengths&#34;&gt;优点 (Strengths)
&lt;/h3&gt;&lt;p&gt;自己对该论文优势的总结&lt;/p&gt;
&lt;h3 id=&#34;潜在缺点可疑点-weaknessesquestions&#34;&gt;潜在缺点/可疑点 (Weaknesses/Questions)
&lt;/h3&gt;&lt;p&gt;模型复杂度？在特定场景的泛化能力？理论基础？&lt;/p&gt;
&lt;h3 id=&#34;启发可借鉴点-insightstakeaways&#34;&gt;启发/可借鉴点 (Insights/Takeaways)
&lt;/h3&gt;&lt;p&gt;该论文值得借鉴的地方&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
